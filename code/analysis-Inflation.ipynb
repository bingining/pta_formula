{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-year NANOGrav Stochastic Background Analysis\n",
    "\n",
    "**Note:** Any changes made in a docker container will be lost when that container is removed, and will not appear if a new container is started.  To make persistent changes to this file copy it to the `local_data/` directory and work from there.\n",
    "\n",
    "## Overview\n",
    "In this notebook we will give several examples of how to reproduce the results from the 11-year NANOGrav stochastic background analysis paper.\n",
    "\n",
    "All models are pre-defined in `models/` with names corresponding to those in Table 1 of the paper. All models and priors are exactly as described in the text and Table 2 of the paper.\n",
    "\n",
    "We will make use of the [`PTMCMCSampler`](https://github.com/jellis18/PTMCMCSampler) package; however, the model functions return a `PTA` that has `get_lnlikelihood` and `get_lnprior` methods that can be used in any sampler that reads in a likelihood and prior function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot import PINT? Meh...\n",
      "Do not have acor package\n"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_pulsars, get_pulsars_ipta, setup_sampler, PostProcessing, bayes_fac\n",
    "from models import models\n",
    "# from models.optimal_statistic import OptimalStatistic\n",
    "\n",
    "# from omegagw_funcs import fpbh_sol, log10\n",
    "from numpy import log10\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pulsars\n",
    "\n",
    "In this step we use the convienience function `get_pulsars` to read in the 34 pulsars used in the NANOGrav analysis. This can take several minutes as the data sets are quite large.\n",
    "\n",
    "This returns a list of `enterprise` `Pulsar` objects that will be used in setting up our PTA in the next step.\n",
    "\n",
    "By default this will use the 34 pulsars from the NANOGrav analysis and DE436 ephemeris but you can pass keyword arguments `psrlist` (a list of pulsar names to use in the analysis) and `ephem` (a string such as 'DE436') for the ephemeris version.\n",
    "\n",
    "The `get_pulsars` function has a keyword argument `use_cache` that will cache the list of pulsar objects to a file for the given pulsar list (order does not matter) and ephemeris. When called again, the function will look for the cached file and use that if it exists. This will save on run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pulsars from cached file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# psrs = get_pulsars_ipta()\n",
    "psrs = get_pulsars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the model for upper limit run\n",
    "\n",
    "In this step we set up the model. All of these models follow the naming convention in Table 2 of the paper.\n",
    "\n",
    "All models (other than `model_1`, which is for single pulsar noise analyses) have the following arguments:\n",
    "\n",
    "* **psrs**: A list of pulsar objects that we created in the step above\n",
    "* **psd**: The PSD to use for the common signals. The three choices are `powerlaw`, `turnover`, or `spectrum` following the description of section 3.2 in the text. `powerlaw` is the default choice\n",
    "* **gamma_common**: The fixed spectral index value (i.e. 13/3 for SMBHB backgrounds). By default this is set to `None` and the spectral index will vary as a free parameter.\n",
    "* **upper_limit**: Specifies whether or not we are performing an upper limit. If so, we will use *uniform* priors on the red noise and common red noise amplitudes, otherwise we use *log-uniform* priors\n",
    "* **bayesephem**: Specifies whether or not to use the dynamical ephemeris model described in the text.\n",
    "\n",
    "Below we run Model 2A which contains a common red noise signal modeled as a powerlaw with fixed spectral index 13/3. We will include Bayesian ephemeris modeling and compute the upper limit on the common red process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psd = \"sigw23\"\n",
    "# psd = 'powerlaw'\n",
    "pta = models.modelInflation(psrs, bayesephem=True, upper_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the sampler\n",
    "\n",
    "We initialize the sampler the likelihood and prior function\n",
    "from the PTA object. We set up an initial jump covariance matrix\n",
    "with fairly small jumps as this will be adapted as the MCMC runs.\n",
    "\n",
    "We will setup an output directory in `outdir` that will contain\n",
    "the chain (first n columns are the samples for the n parameters \n",
    "and last 4 are log-posterior, log-likelihood, acceptance rate, and\n",
    "an indicator variable for parallel tempering but it doesn't matter\n",
    "because we aren't using parallel tempering).\n",
    "\n",
    "We also output text files with the parameter labels and parameter priors\n",
    "in the same order as the chain output. \n",
    "\n",
    "We then add several custom jump proposals to the mix based on\n",
    "whether or not certain parameters are in the model. These are\n",
    "all either draws from the prior distribution of parameters or\n",
    "draws from uniform distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"local_data/chains/Inflation/\"\n",
    "\n",
    "sampler = setup_sampler(pta, resume=False, outdir=outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample!\n",
    "\n",
    "Now we run the sampler. First we set the number of iterations. For production runs we usually do around 5 million samples. Next we set the initial parameter vector (as that is the form in which the sampler expects the input) by drawing from the prior or our parameters.\n",
    "\n",
    "In running the sampler itself we are setting various weights for different jumps. This is just a relative weighting of how often we will call these types of jumps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "pta.get_lnlikelihood(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpbh=1e0\n",
    "N = int(1e4) # one mega-sample!\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "sampler.sample(x0, N, AMweight=25, SCAMweight=40, DEweight=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze output\n",
    "\n",
    "We read in the chain output and pass it to the PostProcessing class that has some useful plotting methods. Lastly we compute the upper limit on the common red noise process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = np.loadtxt(outdir + '/chain_1.txt')\n",
    "pars = np.loadtxt(outdir + '/pars.txt', dtype=np.unicode_)\n",
    "\n",
    "burn = int(0.1*chain.shape[0])\n",
    "print(chain.shape[0])\n",
    "\n",
    "# chain_test = chain[0: 90000]\n",
    "chain_test = chain\n",
    "pp = PostProcessing(chain_test, pars)\n",
    "pp.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn = int(4e4)\n",
    "burn = int(0.25*chain.shape[0])\n",
    "\n",
    "# mpbh=5, n_sample=1e5\n",
    "\n",
    "indAgwb = list(pars).index('log10_A_VL')\n",
    "plt.hist(chain[burn:, indAgwb], 100);\n",
    "plt.xlabel(r'$\\log_{10}A$')\n",
    "plt.title(r\"$m_{pbh} = 0.1, N_{sample}=1e6, N_{pulsar}=34$\")\n",
    "A_chains = chain[burn:, indAgwb]\n",
    "\n",
    "A95 = 10**np.percentile(A_chains, q=95)\n",
    "print(log10(A95), A95)\n",
    "# plt.savefig('logA_m-2_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTAPolar3",
   "language": "python",
   "name": "ptapolar3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
